{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9314d344",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.dataloader import Dataloader\n",
    "\n",
    "data = Dataloader.load_jsonl(\"data/dataset.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fb0dbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from modules.agents.qa.test_runner import TestRunner\n",
    "from modules.schemas.tests import TestSuiteBase\n",
    "test_runner = TestRunner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb6f2c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = data[\"1873_A\"]\n",
    "test_suite = TestSuiteBase(test_cases=example.private_test_cases,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adf11d0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">pulling manifest\n",
       "</pre>\n"
      ],
      "text/plain": [
       "pulling manifest\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb10b5d5f5874952b980388fa3f5e9fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pulling aeda25e63ebd:   0%|          | 0.00/3.34G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "106f6ea504dc44edb69490ce0e0944b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pulling e0a42594d802:   0%|          | 0.00/358 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "356cb3c2f8db4203a2abbb9949e4c176",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pulling dd084c7d92a3:   0%|          | 0.00/8.43k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e11126957c74d3db0608540b8ee8c60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pulling 3116c5225075:   0%|          | 0.00/77.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae9122f114df45d18ea660657126a891",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pulling b6ae5839783f:   0%|          | 0.00/489 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">verifying sha256 digest\n",
       "</pre>\n"
      ],
      "text/plain": [
       "verifying sha256 digest\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">writing manifest\n",
       "</pre>\n"
      ],
      "text/plain": [
       "writing manifest\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">success\n",
       "</pre>\n"
      ],
      "text/plain": [
       "success\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from modules.ollama import OllamaHandler\n",
    "from modules.agents import *\n",
    "\n",
    "ollama_handler = OllamaHandler(model_name=\"gemma3\")\n",
    "dev = Ellian(ollama_handler)\n",
    "qa = Carlos(ollama_handler)\n",
    "reseacher = Thifany(ollama_handler)\n",
    "judge = Will(ollama_handler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79e8cd65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TestsResult(raw_code='import sys\\n\\ndef solve():\\n    s = input()\\n    if s == \"abc\":\\n        print(\"YES\")\\n        return\\n    \\n    if s == \"acb\":\\n        print(\"YES\")\\n        return\\n    \\n    if s == \"bac\":\\n        print(\"YES\")\\n        return\\n    \\n    if s == \"bca\":\\n        print(\"NO\")\\n        return\\n    \\n    if s == \"cab\":\\n        print(\"NO\")\\n        return\\n    \\n    if s == \"cba\":\\n        print(\"YES\")\\n        return\\n    \\n    print(\"NO\")\\n\\nif __name__ == \"__main__\":\\n    t = int(sys.stdin.readline())\\n    for _ in range(t):\\n        solve()', total_time=0.3979, passed_tests=4, total_tests=4, success_rate=1.0, errors=[])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code = dev.generate_code_from_question_dataset(example)\n",
    "results = test_runner.run(test_suite, code)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25533d91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "429a2f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.agents.orchestrator import Vivi, OrchestratorConfig\n",
    "\n",
    "config = OrchestratorConfig(\n",
    "    model=\"gemma3:latest\",\n",
    "    max_iter=2,\n",
    "    max_retry=3,\n",
    "    dev_verbosity=1,\n",
    "    judge_level=0,\n",
    "    use_buffer=False,\n",
    "    ignore_warnings=True\n",
    ")\n",
    "\n",
    "orchestrator = Vivi(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1cfd5e5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "3 validation errors for Solution\nbest_code\n  Field required [type=missing, input_value={'context': \"This solutio...Otherwise, print \"NO\".'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.12/v/missing\nsuccess_rate\n  Field required [type=missing, input_value={'context': \"This solutio...Otherwise, print \"NO\".'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.12/v/missing\nsolution_history\n  Field required [type=missing, input_value={'context': \"This solutio...Otherwise, print \"NO\".'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.12/v/missing",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValidationError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m code_arch = \u001b[43morchestrator\u001b[49m\u001b[43m.\u001b[49m\u001b[43msolve_question_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexample\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Faculdade\\TCC\\bench\\modules\\agents\\orchestrator.py:64\u001b[39m, in \u001b[36mVivi.solve_question_dataset\u001b[39m\u001b[34m(self, question_dataset)\u001b[39m\n\u001b[32m     62\u001b[39m task = \u001b[38;5;28mself\u001b[39m.researcher.define_task(question_dataset)\n\u001b[32m     63\u001b[39m \u001b[38;5;66;03m# Passo 2 -> Iniciar a resolução da Task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m task = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msolve_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[38;5;66;03m# Passo 3 -> Retornar o código final da Task resolvida\u001b[39;00m\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m task.code\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Faculdade\\TCC\\bench\\modules\\agents\\orchestrator.py:89\u001b[39m, in \u001b[36mVivi.solve_task\u001b[39m\u001b[34m(self, task, iteration)\u001b[39m\n\u001b[32m     84\u001b[39m \u001b[38;5;66;03m# Caso a abordagem sugerida seja de subtasks, vamos resolver cada subtask recursivamente\u001b[39;00m\n\u001b[32m     85\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m ((solve_task_plan.solutions \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) ^ (solve_task_plan.subtasks \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)), \\\n\u001b[32m     86\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mEither solutions or subtasks must be provided, not both\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     88\u001b[39m task = \\\n\u001b[32m---> \u001b[39m\u001b[32m89\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msolution_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msolve_task_plan\u001b[49m\u001b[43m.\u001b[49m\u001b[43msolutions\u001b[49m\u001b[43m.\u001b[49m\u001b[43msolutions\u001b[49m\u001b[43m)\u001b[49m \\\n\u001b[32m     90\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m solve_task_plan.result_type == \u001b[33m'\u001b[39m\u001b[33msolutions\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m solve_task_plan.solutions \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \\\n\u001b[32m     91\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.solve_subtasks(task,solve_task_plan.subtasks,iteration -\u001b[32m1\u001b[39m) \u001b[38;5;66;03m#type: ignore\u001b[39;00m\n\u001b[32m     93\u001b[39m \u001b[38;5;66;03m# Atualiza o template de solução\u001b[39;00m\n\u001b[32m     94\u001b[39m task.template = \u001b[38;5;28mself\u001b[39m.researcher.save_history(task)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Faculdade\\TCC\\bench\\modules\\agents\\orchestrator.py:190\u001b[39m, in \u001b[36mVivi.solution_search\u001b[39m\u001b[34m(self, task, base_solutions)\u001b[39m\n\u001b[32m    188\u001b[39m solutions = []\n\u001b[32m    189\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m solution \u001b[38;5;129;01min\u001b[39;00m base_solutions:\n\u001b[32m--> \u001b[39m\u001b[32m190\u001b[39m     solutions.append(\u001b[43mSolution\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msolution\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel_dump\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    192\u001b[39m \u001b[38;5;66;03m# 2. Incializa variáveis de controle\u001b[39;00m\n\u001b[32m    193\u001b[39m best_solution_rate = -\u001b[32m1.0\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Faculdade\\TCC\\bench\\.venv\\Lib\\site-packages\\pydantic\\main.py:250\u001b[39m, in \u001b[36mBaseModel.__init__\u001b[39m\u001b[34m(self, **data)\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[32m    249\u001b[39m __tracebackhide__ = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m validated_self = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[32m    252\u001b[39m     warnings.warn(\n\u001b[32m    253\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m    254\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    255\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    256\u001b[39m         stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m    257\u001b[39m     )\n",
      "\u001b[31mValidationError\u001b[39m: 3 validation errors for Solution\nbest_code\n  Field required [type=missing, input_value={'context': \"This solutio...Otherwise, print \"NO\".'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.12/v/missing\nsuccess_rate\n  Field required [type=missing, input_value={'context': \"This solutio...Otherwise, print \"NO\".'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.12/v/missing\nsolution_history\n  Field required [type=missing, input_value={'context': \"This solutio...Otherwise, print \"NO\".'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.12/v/missing"
     ]
    }
   ],
   "source": [
    "code_arch = orchestrator.solve_question_dataset(example)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bench",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
